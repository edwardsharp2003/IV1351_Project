\documentclass[a4paper]{scrartcl}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{graphicx}
\usepackage{lastpage}
\usepackage{pgf}
\usepackage{wrapfig}
\usepackage{fancyvrb}
\usepackage{fancyhdr}
\usepackage{hyperref}
\usepackage{amsmath}
\pagestyle{fancy}


% Create header and footer
\headheight 27pt
\pagestyle{fancyplain}
\lhead{\footnotesize{Data Storage Paradigms, IV1351}}
\chead{\footnotesize{Project Report, Task 1}}
\rhead{}
\lfoot{}
\cfoot{\thepage\ (\pageref{LastPage})}
\rfoot{}

\title{Project Report}
\subtitle{Data Storage Paradigms, IV1351}
\author{Edward Sharp, Leo Karsikas}
\date{20-11-2025}

\begin{document}

\maketitle
\noindent\textbf{Project members:} \\ \hfill
Edward Sharp, edwardks@kth.se \\ \hfill
Leo Karsikas, leoka@kth.se \\ \hfill

\noindent\href{https://github.com/edwardsharp2003/IV1351_Project}{\textbf{GitHub repository link}}

\section*{Declaration:}

By submitting this assignment, it is hereby declared that all group members listed above have contributed to the solution. It is also declared that all project members fully understand all parts of the final solution and can explain it upon request.

It is furthermore declared that the solution below is a contribution by the project members only, and specifically that no part of the solution has been copied from any other source (except for lecture slides at the course IV1351), no part of the solution has been provided by someone not listed as a project member above, and no part of the solution has been generated by a system.

\section{Introduction}

The primary objective of this project was to perform a conceptual design of a database and later bridge it into a practical database implementation.
The task involved translating a pre-defined, and rather sparse, conceptual model into a fully realised logical and physical database model, whilst ensuring the result is robust and normalised.\\ 

\noindent The project was divided into a mandatory and higher grade part, both of which are addressed in this report.

\subsection{Mandatory requirements}
The core requirements were to design a logical model using crow's foot notation that accurately represents the entities and relationships described in the project description. 
The model had to adhere to the third normal form, or if not, have a good reason not to. 
The project also required the creation of a functional database using SQL.

\subsection{Higher grade part}
The database had to contain all necessary business rules and constants within the database itself, rather than relying on storing them in an external applications logic. 
This includes storing configurational data, such as the limit of how many courses a teacher may be a part of per period. 
The model also had to handle changes in data, for example, it needed to handle the fact that an employees salary could change over time and track it. Another example of this is the fact that the course layout of a course could change, for example, by adjusting the HP the course gives.\\

\noindent We worked on the project by ourselves, only consulting within the group.

\section{Literature Study}

The preparation for the \textbf{Task 1} began with going through all of the given material. Among them are lectures on normalisation and logical and physical models from Canvas for module 1 and also from the fifth to eighth chapters from \textit{Fundamentals in Databases} book. The slides from the lab session were also helpful for this report.\newline   

\noindent The comprehended information was then later used during the creation of the logical and physical model, and also creation of the PostgreSQL Database. The recorded lecture with a step-by-step guide to the model was also reviewed. 

\section{Method}
For this project, a couple of tools were used to implement the \textit{Logical and Physical models} and the database. The logical and physical model was made using Astah Professional, and the database was made using PostgreSQL. The project group followed the setup steps provided in the software section of the Canvas page. In addition, a GitHub repository was created to further encourage collaboration in the project group and make the solution available to the examiner.

\subsection{Logical and the Physical model}
Since the whole task revolves around the creation of a Logical and Physical model, the recorded lecture was carefully followed together with the tips and tricks provided for the task. \newline 

\noindent The project group started with the exploration of the Conceptual Model provided for the task, and after that continued with adding necessary attributes, such as visibility for NOT NULL, key attributes, and types in the column row.


\subsection{Primary and Foreign Keys}
The key part of the Model is focusing on specifying the correct Primary keys and Foreign Keys between tables. To decide on the correct key for the table, discussion was encouraged within the group to provide the group with the opinions and insights from each group member.\newline 

\noindent Moreover, a focus on the cardinality of each relation was made during the creation of each new table, and later reviewed during the completion of the whole model. 

\subsection{Normalisation}
The resulting model was continuously checked against the rules of the \textbf{Third Normal Form (3NF)}.
The group specifically examined relationships to eliminate dependencies where a non-key attribute depends on another non-key attribute (transitive dependencies). 
Furthermore, to satisfy 1NFs requirement that every column in every row must contain only an atomic value, 
Complex many-to-many relationships were checked and, at times, resolved through the creation of explicit junction tables.

\subsection{Implementation of Business Rules and Salary History}
After the structural design, the group focused on integrating the specified business logic into the physical model.
This involved creating specific tables to store numerical constants, such as the maximum number of courses an employee can teach in a given period. 
The constraint was enforced using a PSQL Trigger designed to check the data during insertion.
The model was also adopted to handle changes over time by creating dedicated history tables and implementing versioning on the course\_layout.

\subsection{Creation of the database}

Creation of the database was made after the first SQL draft export from Astah to setup the database.\newline

\noindent The group decided to use a Python script to generate the required data for the database, since the provided tool for generating data was insufficient or too complex to use for the project, given the time constraints of the project.\newline 

\noindent After all of the steps mentioned above, the project group consulted with the assessment criteria document for this task to verify the validity of the proposed solution. 

\section{Result}
The diagram presented in \autoref{fig:lpmodel}  represents the proposed solution for both the Mandatory Part of the task and the Higher grade Part of the task. The ER diagram follows crown notation and contains attributes, entities, relations, and notes.\newline 

\begin{figure}[htbp]
    \centering
    \includegraphics[width=1\linewidth]{media/lpmodel.png}
    \caption{Logical and Physical Model}
    \label{fig:lpmodel}
\end{figure}


 \noindent To ensure the uniqueness of primary keys, \texttt{INT GENERATED ALWAYS AS IDENTITY} was used for all dynamic, transactional tables (e.g., \texttt{employee}, \texttt{person}, and \texttt{course\_instance}). This ensures a unique identifier is generated automatically for every new record. 
To preserve predictability, the \texttt{study\_period\_id} column was defined as a standard \texttt{INT} instead of utilizing \texttt{GENERATED ALWAYS AS IDENTITY}. 
This choice was made so that the ID can directly correlate to the period, (e.g., ID 1 always means period 1).
If \texttt{study\_period\_id} was made to \texttt{INT GENERATED ALWAYS AS IDENTITY}, if a study period was accidentally deleted and later added back again, the ID for, for example, period 1, would change from 1 to something else. 

\noindent Cardinality for each relationship has been defined according to its nature, and also considered if the relationship is identifying or non-identifying. 
\subsection{Database}

The setup instructions for the database are described in \noindent\href{https://github.com/edwardsharp2003/IV1351_Project/blob/main/seminar_1/task1/Instruction.md}{\textbf{Instruction.md}}. \\
Note: the instructions are made for Mac/Linux, and therefore cannot guarantee compatibility with Windows terminals. \\

\noindent The instructions file explains how to insert the setup script into the psql terminal, and also how to insert the generated data into the created database. 

\noindent In the following figure and screenshot from the psql terminal is presented \autoref{fig:psql}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.5\linewidth]{media/psql.png}
    \caption{Screenshot from the psql terminal}
    \label{fig:psql}
\end{figure}
\newpage 

\section{Discussion}

The Logical and Physical model was based on the project description provided for the task, and thoroughly reviewed during the later stages of the project, to avoid missing details mentioned in the project description and in the assessment criteria. Among them, following the crown convention given in the Conceptual Model template, and also the self-explanatory naming of both table and attribute names.\\ 

\noindent For all of the columns in the model, primary and foreign keys are specified, with consideration of uniqueness. This is necessary for generating an ID for the majority of the primary keys. Moreover, the types of columns in the model were modified with regard to compatibility with the PostgreSQL database, and therefore, the use of the previously mentioned \textit{INT ALWAYS GENERATED AS IDENTITY} was suitable for the implementation. \\ 

\noindent In regard to the relationship between the tables, do all of them have a specified cardinality and identifying or non-identifying relationship. Moreover, the majority of the relations have a name
or an ”action” that describes what the relations do in combination with the entity it
belongs to.  

\subsection{Choice of Data Types}
Choosing between data types for an attribute was sometimes more obvious than other times.
For most values containing strings of variable length, for example, a persons name, course codes, and course names, \texttt{VARCHAR(n)} was used.
The maximum length, $n$, was altered depending on the situation, for example, a course code is usually much shorter than the course name. 
In our case, these were set to \texttt{VARCHAR(10)} for course code, and \texttt{VARCHAR(500)} for course name.
For \texttt{personal\_number}, \texttt{CHAR(11} was used instead to ensure a uniform format for the personal numbers.
The opted format for personal numbers was yymmdd-xxxx, often referred to as a 10-length personal number, but because of the dash (-) the length becomes 11.\\

\noindent Other data types worth mentioning are the use of \texttt{DECIMAL}.
The factor, HP of a course, and salary\_amount all used \texttt{DECIMAL} as their data types. 
This choice was made because these values are not integers, e.g., they can have decimal values, and \texttt{FLOAT} or \texttt{REAL} was avoided because of floating point errors.
For example, \texttt{FLOAT} can suffer from binary rounding issues, where $0.1 + 0.2 \neq 0.3$.
By using for example \texttt{DECIMAL (4, 2} for factor, there will be 4 total positions of value, where 2 of them are beyond the decimal place, for example $3.20$ or at max $99.99$.

\subsection{History Preservation and Versioning}
To handle changing course layouts, we designed the \texttt{course\_layout} table to accept multiple records for the same \texttt{course\_code}, distinguishing them by including a \texttt{valid\_from} date. 
Similarly, the \texttt{salary} column was removed from the \texttt{employee} table and replaced with the dedicated \texttt{salary\_history} entity. 
These changes ensure that when a course's HP or a teacher's salary is updated, a new record is created rather than overwriting the old one.\\

\noindent The main advantage to keeping multiple versions of data is that it guarantees data accuracy for all historical transactions. 
Since attributes like salary or course HP are tied to specific effective dates, creating a new record instead of overwriting the old one ensures that past records, for example a student's 2022 transcript or a 2023 payroll calculation, remain correct. 
Furthermore, it completely removes the risk of update anomalies, as a change in one version of a course definition cannot accidentally corrupt past records.\\

\noindent There are however disadvantages to this implementation. 
Firstly, it increases the complexity of queries. 
A developer can no longer simply select the employee's salary from the main table. 
Instead, they must use filtering, for example selecting the record with the maximum \texttt{valid\_from date} to find the current rate. 
Secondly, since every minor change in a course layout or an employee's raise requires a new, complete record, the database will naturally grow faster. 

\subsection{Logic and Business Rules}
A core requirement was that the database must manage all necessary data and logic, leaving no data to be stored in for example an application.
This involves two major points: the storage of the constant value '4' and the enforcement of the rule.\\

\noindent The constraint that "a teacher can teach up to 4 courses in a particular period" was implemented by storing the value 4 in the \texttt{system\_rules} table. 
This achieves the goal of keeping all crucial data within the database itself.
The enforcement of the course limit is handled by the \texttt{check\_allocation\_limit} PSQL trigger, which is attached to the \texttt{activity\_allocation} table. 
This ensures the business rule is enforced at the data layer.
The trigger logic specifically: 
\begin{itemize}
    \item Retrieves the dynamic max limit from \texttt{system\_rules}
    \item Counts the distinct \texttt{course\_instance\_id}s associated with the employee in the current \texttt{study\_period\_id} 
    \item Aborts the transaction and raises an exception if the limit is exceeded.
\end{itemize}
This implementation ensures that the business requirement is met by the physical model.

\subsection{Normalisation violation}
The overall model is designed to achieve Third Normal Form (3NF), but a deliberate trade-off was made in the design of the \texttt{address} entity, resulting in a minor, but deliberate, violation of 3NF.\\

\noindent The \texttt{address} table stores the full street address. 
If we were to strictly adhere to 3NF, the following transitive dependency would need to be resolved:

$$
\text{Address ID} \to \text{Postal Code} \to \text{City}
$$
\\
In a pure 3NF model, the city name is dependent on the postal code, not the primary key (\texttt{address\_id}). 
Therefore, the city should be moved to a separate \texttt{postal\_codes} lookup table.\\

\noindent The decision to keep the \texttt{city} directly within the \texttt{address} table is mainly due to simplicity in data entry.
Creating and maintaining a full and comprehensive postal code database, that ideally covers address formats of different countries, introduces significant complexity that outweighs the small benefit of eliminating text redundancy in this application.

\section{Comments About the Course}


We approximately spent a total of 4 sessions of 4--5 hours each, where we met up and worked on the seminar together.


\end{document}
